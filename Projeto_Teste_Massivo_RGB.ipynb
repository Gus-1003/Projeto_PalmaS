{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gus-1003/Projeto_PalmaS/blob/main/Projeto_Teste_Massivo_RGB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7hz_yfjqh0zq"
      },
      "source": [
        "## Importando Bibliotecas:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "AEhdBtYDfAGN"
      },
      "outputs": [],
      "source": [
        "'''importando a biblioteca Pandas -> usada para análise e manipulação de dados.'''\n",
        "import pandas as pd\n",
        "\n",
        "'''importando a biblioteca NumPy -> usada para trabalhar com matrizes e operações matemáticas.'''\n",
        "import numpy as np\n",
        "\n",
        "'''importando a biblioteca Matplotlib -> usada para criar visualizações de dados.'''\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "'''importando a biblioteca OpenCV, uma biblioteca de código aberto -> amplamente utilizada para processamento de imagens.'''\n",
        "import cv2\n",
        "\n",
        "'''importando a classe KMeans da biblioteca Scikit-Learn, que é usada para realizar a clusterização de dados. \n",
        "A clusterização é uma técnica de aprendizado não supervisionado que agrupa dados semelhantes em clusters.'''\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "'''importando a função cv2_imshow do Google Colab, que é usada para exibir imagens dentro do ambiente de notebook.'''\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "'''A biblioteca glob é utilizada para encontrar todos os caminhos que correspondem a um determinado padrão. \n",
        "No contexto deste código, provavelmente será utilizada para encontrar imagens em um diretório.'''\n",
        "import glob\n",
        "\n",
        "import warnings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U1SSb1wyjQQ0",
        "outputId": "ccf09f9a-40a5-4dd1-d4d3-137a00c98601"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/MyDrive/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e3oYViwgSAj0"
      },
      "source": [
        "Essas duas linhas de código são específicas para o ambiente do Google Colab e são usadas para montar o Google Drive na sessão do Colab.\n",
        "  * A primeira linha importa a biblioteca drive do Google Colab, que contém a função mount, que é utilizada para montar o Google Drive na sessão do Colab. \n",
        "  * A segunda linha chama a função mount e monta o Google Drive em uma pasta específica, neste caso em /content/drive/MyDrive/.\n",
        "\n",
        "É importante destacar que essas duas linhas podem ser ignoradas se você estiver executando o código em um ambiente diferente do Google Colab ou se não precisar acessar arquivos armazenados no Google Drive."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zuNRwvQdh42n"
      },
      "source": [
        "## Lendo Imagem:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "R_xCtIZ-h7xN"
      },
      "outputs": [],
      "source": [
        "# Variável path_list armazena uma lista de caminhos de arquivos que correspondem ao padrão especificado.\n",
        "#path_list = glob.glob('/content/drive/MyDrive/Pesquisa_Cochonilha/Base_Imagens/Editadas_Cortadas/Selecionadas/*.jpg') \n",
        "path_list = glob.glob('/content/drive/MyDrive/Pesquisa_Cochonilha/Base_Imagens/Editadas_Cortadas/*.jpg')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Segmentação do Fundo:"
      ],
      "metadata": {
        "id": "NCgy5IQkiueU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loop que processa cada arquivo na lista de caminhos de arquivos.\n",
        "for link in path_list:\n",
        "\n",
        "  warnings.filterwarnings(\"ignore\", message=\"X does not have valid feature names, but KMeans was fitted with feature names\")\n",
        "\n",
        "  # The function cv2.imread() is used to read an image.\n",
        "  im = cv2.imread(link)\n",
        "\n",
        "  # Separa o nome especifico da imagem.\n",
        "  nome_completo = link.split('/')\n",
        "  nome = nome_completo[7].split('.')\n",
        "\n",
        "  # Imprime as fronteiras e identifica as imagens:\n",
        "  print(\"================================================================================\")\n",
        "  print(\"================================================================================\") \n",
        "  print(nome[0])\n",
        "\n",
        "  # Converte a imm para o espaço de cores HSV\n",
        "  hsv = cv2.cvtColor(im, cv2.COLOR_BGR2HSV)\n",
        "\n",
        "  # Define o intervalo de cores verde que você deseja segmentar\n",
        "  lower_green = np.array([40, 50, 50])  # Limite inferior do verde (pode ajustar os valores)\n",
        "  upper_green = np.array([100, 255, 255])  # Limite superior do verde (pode ajustar os valores)\n",
        "\n",
        "  # Cria uma máscara com base nos limites definidos\n",
        "  mask = cv2.inRange(hsv, lower_green, upper_green)\n",
        "\n",
        "  # Aplica a máscara na imm original\n",
        "  result = cv2.bitwise_and(im, im, mask=mask)\n",
        "\n",
        "  cv2_imshow(result)"
      ],
      "metadata": {
        "id": "lfoJ3FyGcK4d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loop que processa cada arquivo na lista de caminhos de arquivos.\n",
        "for link in path_list:\n",
        "\n",
        "  warnings.filterwarnings(\"ignore\", message=\"X does not have valid feature names, but KMeans was fitted with feature names\")\n",
        "\n",
        "  # The function cv2.imread() is used to read an image.\n",
        "  image = cv2.imread(link)\n",
        "\n",
        "  # Separa o nome especifico da imagem.\n",
        "  nome_completo = link.split('/')\n",
        "  nome = nome_completo[7].split('.')\n",
        "\n",
        "  # Imprime as fronteiras e identifica as imagens:\n",
        "  print(\"================================================================================\")\n",
        "  print(\"================================================================================\") \n",
        "  print(nome[0])\n",
        "\n",
        "  # Converte a imagem para o espaço de cores HSV\n",
        "  hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
        "\n",
        "  # Define o intervalo de cores verde que representa o fundo\n",
        "  lower_hue = np.array([176, 50, 50])  # Limite inferior da tonalidade\n",
        "  upper_hue = np.array([186, 255, 255])  # Limite superior da tonalidade\n",
        "\n",
        "\n",
        "  # Cria uma máscara com base nos limites definidos\n",
        "  mask = cv2.inRange(hsv, lower_green, upper_green)\n",
        "\n",
        "  # Inverte a máscara para manter o fundo e remover os insetos\n",
        "  mask_inverse = cv2.bitwise_not(mask)\n",
        "\n",
        "  # Cria uma imagem com fundo preto\n",
        "  result = np.zeros_like(image)\n",
        "\n",
        "  # Copia apenas os pixels da imagem original onde a máscara é não zero\n",
        "  result[mask_inverse > 0] = image[mask_inverse > 0]\n",
        "\n",
        "  cv2_imshow(result)"
      ],
      "metadata": {
        "id": "iOUb5f3rgB5J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3sAUDJFgcGyB"
      },
      "source": [
        "## Processamento em Massa:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "n8gWoiv1YDTt"
      },
      "outputs": [],
      "source": [
        "def extract_image(thresh, cnt):\n",
        "  # Cria uma imagem em branco com as mesmas dimensões da imagem original\n",
        "  im_blank = np.zeros(im.shape, np.uint8) \n",
        "\n",
        "  # Desenha o contorno especificado na imagem em branco\n",
        "  cv2.drawContours(im_blank, [cnt], -1, 255, -1)\n",
        "\n",
        "  # Cria uma máscara que corresponde aos pixels dentro do contorno\n",
        "  mask = im_blank == 255\n",
        "\n",
        "  # Aplica a máscara na imagem original para obter apenas os pixels dentro do contorno\n",
        "  im_filter = im[mask]\n",
        "\n",
        "  # Retorna a nova imagem\n",
        "  return im_filter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SeHY84HeSwRE"
      },
      "outputs": [],
      "source": [
        "# Loop que processa cada arquivo na lista de caminhos de arquivos.\n",
        "for link in path_list:\n",
        "\n",
        "  warnings.filterwarnings(\"ignore\", message=\"X does not have valid feature names, but KMeans was fitted with feature names\")\n",
        "\n",
        "  # The function cv2.imread() is used to read an image.\n",
        "  im = cv2.imread(link)\n",
        "\n",
        "  # Separa o nome especifico da imagem.\n",
        "  nome_completo = link.split('/')\n",
        "  nome = nome_completo[7].split('.')\n",
        "\n",
        "  # Imprime as fronteiras e identifica as imagens:\n",
        "  print(\"================================================================================\")\n",
        "  print(\"================================================================================\") \n",
        "  print(nome[0])\n",
        "\n",
        "  # Instrução para descobrir o tamanho da dimensão da imagem (Linhas x Colunas)\n",
        "  print('Dim:' + str(im.shape))\n",
        "\n",
        "  # Cria uma cópia da imagem original.\n",
        "  compara = im.copy()\n",
        "\n",
        "  # Converte a imagem para o espaço de cores HSV\n",
        "  hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
        "\n",
        "  # Define o intervalo de cores verde que representa o fundo\n",
        "  lower_hue = np.array([176, 50, 50])  # Limite inferior da tonalidade\n",
        "  upper_hue = np.array([186, 255, 255])  # Limite superior da tonalidade\n",
        "\n",
        "\n",
        "  # Cria uma máscara com base nos limites definidos\n",
        "  mask = cv2.inRange(hsv, lower_green, upper_green)\n",
        "\n",
        "  # Inverte a máscara para manter o fundo e remover os insetos\n",
        "  mask_inverse = cv2.bitwise_not(mask)\n",
        "\n",
        "  # Cria uma imagem com fundo preto\n",
        "  result = np.zeros_like(image)\n",
        "\n",
        "  # Copia apenas os pixels da imagem original onde a máscara é não zero\n",
        "  result[mask_inverse > 0] = image[mask_inverse > 0]\n",
        "\n",
        "  # separa uma imagem em seus canais de cor individuais (B, G, R)\n",
        "  im_split_channels = cv2.split(result)\n",
        "\n",
        "  # realiza a mesma operação de separação de canais de cor em BGR e atribui cada canal de cor a uma variável correspondente\n",
        "  (b, g, r) = cv2.split(result)\n",
        "\n",
        "  # Aplica um filtro de média à imagem.\n",
        "  b_blur = cv2.blur(b, (3, 3))\n",
        "\n",
        "  # Aplica um filtro de borramento com kernel de 5x5\n",
        "  b_gaussian = cv2.GaussianBlur(b_blur, (5, 5), 0)  \n",
        "\n",
        "  # Aplica uma limiarização com método de Otsu à imagem.\n",
        "  ret, thresh = cv2.threshold(b_gaussian, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "\n",
        "  contours, hierarchy = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "  rows, columns = thresh.shape\n",
        "  areaImagem = rows*columns\n",
        "\n",
        "  # Inicializa a variável areaOcupada como zero\n",
        "  areaOcupada = 0\n",
        "\n",
        "  # Loop sobre a lista de contornos encontrados na imagem binarizada\n",
        "  for qtd in range(len(contours)):\n",
        "    # Calcula a área correspondente ao contorno atual e adiciona à variável areaOcupada\n",
        "    atual = cv2.contourArea(contours[qtd])\n",
        "    areaOcupada = areaOcupada + atual\n",
        "\n",
        "  # Exibe algumas informações relevantes na tela\n",
        "  print(\"areaImagem = \", areaImagem)  # Exibe a área total da imagem binarizada\n",
        "  print('Foram encontrados ' + str(len(contours)) + ' objetos com seus contornos')  # Exibe a quantidade de objetos encontrados\n",
        "  print('Area total ocupada: ' + str(areaOcupada))  # Exibe a área total ocupada pelos objetos\n",
        "  print('Relação infestação/área total: ' + str((areaOcupada/(rows*columns))*100) + ' %')  # Exibe a relação entre a área ocupada pelos objetos e a área total da imagem binarizada\n",
        "\n",
        "  # Desenha os contornos encontrados na imagem original\n",
        "  cv2.drawContours(im, contours, -1, (255,0,0), 2)  # Desenha os contornos em cor magenta com largura de linha 2 pixels\n",
        "\n",
        "  areas = [] # Armazena a área de cada objeto\n",
        "  perimeters = [] # Armazena o perímetro de cada objeto\n",
        "  centroids_x = [] # Armazena as coordenadas x do centróide de cada objeto\n",
        "  centroids_y = [] # Armazena as coordenadas y do centróide de cada objeto\n",
        "  aspect_ratio = [] # Armazena a relação entre largura e altura do retângulo de contorno de cada objeto\n",
        "  extent = [] # Armazena a razão entre a área do contorno e a área do retângulo de contorno de cada objeto\n",
        "  solidity = [] # Armazena a razão entre a área do contorno e a área do casco convexo de cada objeto\n",
        "  equivalent_diameter = [] # Armazena o diâmetro equivalente (em pixels) do círculo com a mesma área de cada objeto\n",
        "\n",
        "  # r_mean, r_min, r_max e r_std: armazenarão a média, o mínimo, o máximo e o desvio padrão dos valores do canal vermelho (R) de cada objeto encontrado na imagem.\n",
        "  r_mean = []\n",
        "  r_min = []\n",
        "  r_max = []\n",
        "  r_std = []\n",
        "\n",
        "  # g_mean, g_min, g_max e g_std: armazenarão a média, o mínimo, o máximo e o desvio padrão dos valores do canal verde (G) de cada objeto encontrado na imagem.\n",
        "  g_mean = []\n",
        "  g_min = []\n",
        "  g_max = []\n",
        "  g_std = []\n",
        "\n",
        "  # b_mean, b_min, b_max e b_std: armazenarão a média, o mínimo, o máximo e o desvio padrão dos valores do canal azul (B) de cada objeto encontrado na imagem.\n",
        "  b_mean = []\n",
        "  b_min = []\n",
        "  b_max = []\n",
        "  b_std = []\n",
        "\n",
        "  width = [] # Armazena a largura do retângulo de contorno de cada objeto\n",
        "  height = [] # Armazena a altura do retângulo de contorno de cada objeto\n",
        "  angle = [] # Armazena o ângulo (em graus) do retângulo de contorno de cada objeto\n",
        "  radius = [] # Armazena o raio do círculo de contorno de cada objeto\n",
        "\n",
        "  # Para cada contorno da lista de contornos:\n",
        "  for c in contours:\n",
        "\n",
        "    # Momentos do objeto\n",
        "    M = cv2.moments(c)\n",
        "\n",
        "    # Área do objeto\n",
        "    areas.append(M['m00'])\n",
        "\n",
        "    # Perímetro do objeto\n",
        "    perimeters.append(cv2.arcLength(c,True)) #if not convex, False\n",
        "\n",
        "    # Proporção de aspecto do objeto\n",
        "    x,y,w,h = cv2.boundingRect(c)\n",
        "    aspect_ratio.append(float(w)/h)\n",
        "    width.append(w)\n",
        "    height.append(h)\n",
        "\n",
        "    # Ângulo e raio mínimo envolvente em torno do objeto\n",
        "    rect = cv2.minAreaRect(c)\n",
        "    circle = cv2.minEnclosingCircle(c)\n",
        "    angle.append(rect[2])\n",
        "    radius.append(circle[1])\n",
        "\n",
        "    # Extensão do objeto (razão entre a área do objeto e a área do retângulo envolvente mínimo)\n",
        "    rect_area = w*h\n",
        "    if rect_area > 0:\n",
        "        extent.append(M['m00']/rect_area)\n",
        "    else: \n",
        "        extent.append(0)\n",
        "\n",
        "    # Solidez do objeto (razão entre a área do objeto e a área de seu casco convexo)\n",
        "    hull = cv2.convexHull(c)\n",
        "    hull_area = cv2.contourArea(hull)\n",
        "    if hull_area > 0:\n",
        "        solidity.append(M['m00']/hull_area)\n",
        "    else:\n",
        "        solidity.append(0)\n",
        "\n",
        "    # Diâmetro equivalente do objeto (diâmetro do círculo cuja área é a mesma da área do objeto)\n",
        "    equivalent_diameter = np.sqrt(4*M['m00']/np.pi)\n",
        "\n",
        "    # Cálculo das coordenadas do centroide do objeto\n",
        "    if M['m00'] != 0:\n",
        "        centroids_x.append(M['m10']/M['m00'])\n",
        "        centroids_y.append(M['m01']/M['m00'])\n",
        "    else:\n",
        "        centroids_x.append(0)\n",
        "        centroids_y.append(0)\n",
        "        \n",
        "    # Extração das informações de cor do objeto nas bandas R, G e B\n",
        "    r = extract_image(im_split_channels[2], c)\n",
        "    g = extract_image(im_split_channels[1], c)\n",
        "    b = extract_image(im_split_channels[0], c)\n",
        "\n",
        "    # Cálculo das estatísticas de cor para as bandas R, G e B\n",
        "    # Canal vermelho:\n",
        "    r_mean.append(np.mean(r))\n",
        "    r_max.append(np.max(r))\n",
        "    r_min.append(np.min(r))\n",
        "    r_std.append(np.std(r))\n",
        "\n",
        "    # Canal verde:\n",
        "    g_mean.append(np.mean(g))\n",
        "    g_max.append(np.max(g))\n",
        "    g_min.append(np.min(g))\n",
        "    g_std.append(np.std(g))\n",
        "\n",
        "    # Canal Azul:\n",
        "    b_mean.append(np.mean(b))\n",
        "    b_max.append(np.max(b))\n",
        "    b_min.append(np.min(b))\n",
        "    b_std.append(np.std(b))\n",
        "\n",
        "  features = {'r_mean': r_mean, 'r_max': r_max, 'r_min': r_min, 'r_std': r_std,\n",
        "            'g_mean': g_mean, 'g_max': g_max, 'g_min': g_min, 'g_std': g_std,\n",
        "            'b_mean': b_mean, 'b_max': b_max, 'b_min': b_min, 'b_std': b_std,\n",
        "            'area': areas, 'perimiter': perimeters, 'aspect_ratio': aspect_ratio, \n",
        "            'extent': extent, 'solidity': solidity, 'equivalent_diameter': equivalent_diameter\n",
        "  } \n",
        "\n",
        "  df = pd.DataFrame(features)\n",
        "\n",
        "  # n_clusters: Define o número de clusters:\n",
        "  n_clusters = 3\n",
        "\n",
        "  if len(df) >= n_clusters:\n",
        "    kmeans = KMeans(n_clusters=n_clusters, init='k-means++', n_init=10)\n",
        "    kmeans.fit(df)\n",
        "  else:\n",
        "    n_clusters = 1\n",
        "    kmeans = KMeans(n_clusters=n_clusters, init='k-means++', n_init=10)\n",
        "    kmeans.fit(df)\n",
        "    print(\"Número de amostras é menor que o número de clusters desejados.\")\n",
        "\n",
        "  im2 = compara.copy()\n",
        "\n",
        "  # Lista vazia conts para armazenar os contornos agrupados por classes\n",
        "  conts = [[],[],[],[]] #contour list\n",
        "\n",
        "  # Loop através dos contornos e prevê sua classe utilizando KMeans.predict\n",
        "  for cont, cnt in enumerate(contours):\n",
        "    # Adiciona o contorno na lista correspondente à sua classe\n",
        "    class_ = kmeans.predict([df.iloc[cont]])[0]\n",
        "    conts[class_].append(cnt)\n",
        "\n",
        "  # Desenha os contornos agrupados por classe na imagem   \n",
        "  if n_clusters == 3:\n",
        "    im2 = cv2.drawContours(im2, conts[0], -1, (255, 0, 0), thickness=2) # Azul\n",
        "    im2 = cv2.drawContours(im2, conts[1], -1, (0, 255, 0), thickness=2) # Laranja\n",
        "    im2 = cv2.drawContours(im2, conts[2], -1, (0, 0, 255), thickness=2) # Verde\n",
        "  elif n_clusters == 2:\n",
        "    im2 = cv2.drawContours(im2, conts[0], -1, (255, 255, 0), thickness=2)\n",
        "    im2 = cv2.drawContours(im2, conts[1], -1, (0, 255, 255), thickness=2)\n",
        "\n",
        "  print(\"O numero de cluster escolhido foi: \" + str(n_clusters))\n",
        "  print()\n",
        "  print('class 0: ' + str(len(conts[0])) + ' individuals')\n",
        "  print('class 1: ' + str(len(conts[1])) + ' individuals')\n",
        "  print('class 2: ' + str(len(conts[2])) + ' individuals')\n",
        "  print('class 3: ' + str(len(conts[3])) + ' individuals')\n",
        "\n",
        "  cv2_imshow(cv2.hconcat([compara, im, im2]))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}